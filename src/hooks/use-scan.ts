
import { useState, useCallback, useRef } from 'react';
import { useToast } from './use-toast';
import { validationService } from '@/services/validation/validationService';
import { reportingService } from '@/services/reporting/reportingService';
import { auditService } from '@/modules/audit/services/auditService';

// Define ScanDetails type
export interface ScanDetails {
  current_url: string;
  pages_scanned: number;
  estimated_pages: number;
  stage: string;
  progress: number;
}

/**
 * Hook for handling website scanning functionality
 */
export const useScan = (url: string, onPageCountUpdate?: (count: number) => void) => {
  const [isScanning, setIsScanning] = useState(false);
  const [scanDetails, setScanDetails] = useState<ScanDetails>({
    current_url: '',
    pages_scanned: 0,
    estimated_pages: 0,
    stage: 'idle',
    progress: 0
  });
  const [pageStats, setPageStats] = useState<{
    total: number;
    html: number;
    images: number;
    other: number;
  }>({
    total: 0,
    html: 0,
    images: 0,
    other: 0
  });
  const [sitemap, setSitemap] = useState<string | null>(null);
  const [taskId, setTaskId] = useState<string | null>(null);
  const { toast } = useToast();
  const pollingIntervalRef = useRef<NodeJS.Timeout | null>(null);

  // Start scanning process
  const startScan = useCallback(async (useSitemap: boolean = true) => {
    console.log('üîß useScan.startScan called for URL:', url, 'with sitemap:', useSitemap);
    
    if (!url) {
      console.error('‚ùå Cannot start scan: URL is empty');
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "URL –Ω–µ —É–∫–∞–∑–∞–Ω",
        variant: "destructive",
      });
      return null;
    }

    if (!validationService.validateUrl(url)) {
      console.error('‚ùå URL validation failed:', url);
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç URL",
        variant: "destructive",
      });
      return null;
    }

    try {
      console.log('üöÄ Starting scan process...');
      setIsScanning(true);
      setScanDetails({
        current_url: url,
        pages_scanned: 0,
        estimated_pages: 500000,
        stage: '–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∫ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—é',
        progress: 0
      });

      // Format URL
      const formattedUrl = validationService.formatUrl(url);
      console.log('üìù Formatted URL:', formattedUrl);
      
      // Start audit via edge function
      console.log('üì° Calling audit-start edge function with:', { 
        url: formattedUrl, 
        type: 'quick', 
        maxPages: 100 
      });
      const response = await auditService.startAudit(formattedUrl, {
        type: 'quick',
        maxPages: 100
      });
      
      console.log('üì• audit-start response received:', response);
      
      const crawlTaskId = response.task_id;
      if (!crawlTaskId) {
        console.error('‚ùå No task_id in response:', response);
        throw new Error('Empty task ID returned');
      }
      
      console.log('‚úÖ Audit started successfully with task ID:', crawlTaskId);
      setTaskId(crawlTaskId);
      
      // Track polling start time for timeout detection
      const pollingStartTime = Date.now();
      const POLLING_TIMEOUT = 2 * 60 * 1000; // 2 minutes timeout
      let lastUpdateTime = Date.now();
      let lastPagesScanned = 0;
      
      // Start progress polling
      const pollInterval = setInterval(async () => {
        try {
          const statusResponse = await auditService.getAuditStatus(crawlTaskId);
          
          const statusCurrent = statusResponse.url;
          const pagesScanned = statusResponse.pages_scanned;
          const totalPages = statusResponse.total_pages;
          const status = statusResponse.status;
          
          const progressValue = statusResponse.progress;
          
          // Check for timeout - if no progress for 2 minutes
          const currentTime = Date.now();
          const timeSinceStart = currentTime - pollingStartTime;
          
          if (pagesScanned !== lastPagesScanned) {
            lastUpdateTime = currentTime;
            lastPagesScanned = pagesScanned;
          }
          
          const timeSinceLastUpdate = currentTime - lastUpdateTime;
          
          // If stuck for more than 2 minutes OR total time exceeds timeout
          if (timeSinceLastUpdate > POLLING_TIMEOUT || timeSinceStart > POLLING_TIMEOUT * 3) {
            console.error('‚è±Ô∏è Scan timeout: No progress detected');
            clearInterval(pollInterval);
            setIsScanning(false);
            
            toast({
              title: "–û—à–∏–±–∫–∞ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
              description: "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞—Å—Ç—Ä—è–ª–æ. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏—Ç—å –∑–∞–Ω–æ–≤–æ.",
              variant: "destructive",
            });
            return;
          }
          
          setScanDetails({
            current_url: statusCurrent,
            pages_scanned: pagesScanned,
            estimated_pages: totalPages,
            stage: status === 'completed' 
              ? '–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ' 
              : `–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ (${progressValue}%)`,
            progress: progressValue
          });
          
          // Update parent component with page count if callback provided
          if (onPageCountUpdate && pagesScanned) {
            onPageCountUpdate(pagesScanned);
          }
          
          // If scan is complete, clean up and generate sitemap
          if (status === 'completed') {
            clearInterval(pollInterval);
            pollingIntervalRef.current = null;
            
            // Get URLs from the status response or use the current URL
            const pageUrls = [statusResponse.url]; // In a real implementation, you would get all discovered URLs
            
            const domain = validationService.extractDomain(url);
            
            // Generate sitemap using the reportingService
            const sitemapXml = reportingService.generateSitemapXml(domain, pageUrls);
            setSitemap(sitemapXml);
            
            // Show completion state with 100% progress
            setScanDetails(prev => ({
              ...prev,
              stage: '–ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω',
              progress: 100
            }));
            
            toast({
              title: "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ",
              description: `–ü—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ ${pagesScanned} —Å—Ç—Ä–∞–Ω–∏—Ü`,
            });
            
            // Wait 3 seconds before hiding the panel to show completion state
            setTimeout(() => {
              setIsScanning(false);
            }, 3000);
          } else if (status === 'failed') {
            clearInterval(pollInterval);
            pollingIntervalRef.current = null;
            setIsScanning(false);
            
            const errorMessage = statusResponse.error || "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Å–∞–π—Ç–∞";
            toast({
              title: "–ê—É–¥–∏—Ç –ø—Ä–µ—Ä–≤–∞–Ω - –¥–æ—Å—Ç—É–ø–Ω—ã —á–∞—Å—Ç–∏—á–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ",
              description: `–ü—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ ${pagesScanned} –∏–∑ ${totalPages} —Å—Ç—Ä–∞–Ω–∏—Ü`,
              variant: "default",
            });
          }
        } catch (error) {
          console.error("Error polling scan status:", error);
          clearInterval(pollInterval);
          setIsScanning(false);
          
          toast({
            title: "–û—à–∏–±–∫–∞",
            description: "–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å—Ç–∞—Ç—É—Å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è",
            variant: "destructive",
          });
        }
      }, 2000);
      
      return crawlTaskId;
    } catch (error) {
      console.error("Error starting scan:", error);
      setIsScanning(false);
      
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
        variant: "destructive",
      });
      
      return null;
    }
  }, [url, toast, onPageCountUpdate]);

  // Handle download sitemap
  const downloadSitemap = useCallback(() => {
    if (!sitemap) {
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "Sitemap –Ω–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω",
        variant: "destructive",
      });
      return;
    }

    try {
      const domain = validationService.extractDomain(url);
      // Use the exportSitemapXml method with the sitemap string
      reportingService.exportSitemapXml(sitemap, domain);
      
      toast({
        title: "–ì–æ—Ç–æ–≤–æ",
        description: "Sitemap.xml —É—Å–ø–µ—à–Ω–æ —Å–∫–∞—á–∞–Ω",
      });
    } catch (error) {
      console.error("Error downloading sitemap:", error);
      
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å sitemap",
        variant: "destructive",
      });
    }
  }, [sitemap, url, toast]);

  // Cancel ongoing scan
  const cancelScan = useCallback(async () => {
    if (!taskId || !isScanning) {
      return;
    }

    try {
      await auditService.cancelAudit(taskId);
      setIsScanning(false);
      
      toast({
        title: "–°–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç–º–µ–Ω–µ–Ω–æ",
        description: "–ü—Ä–æ—Ü–µ—Å—Å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è –±—ã–ª –æ—Ç–º–µ–Ω–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º",
      });
    } catch (error) {
      console.error("Error cancelling scan:", error);
      
      toast({
        title: "–û—à–∏–±–∫–∞",
        description: "–ù–µ —É–¥–∞–ª–æ—Å—å –æ—Ç–º–µ–Ω–∏—Ç—å —Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ",
        variant: "destructive",
      });
    }
  }, [taskId, isScanning, toast]);

  return {
    isScanning,
    scanDetails,
    pageStats,
    sitemap,
    taskId,
    startScan,
    cancelScan,
    downloadSitemap
  };
};
